{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66157c1b-6a86-416f-8729-bd8bddbfc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Column\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe12357-9462-4285-97ed-5ec54b5d13dc",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e35e8c-5dd6-4638-a6d9-bc0597219ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/12 21:07:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"HelloPySpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6374be22-8a22-4650-8265-ccaa68a64c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.version == 3.1.2\n"
     ]
    }
   ],
   "source": [
    "print(\"spark.version ==\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81399-494a-463a-8ad3-e7182c432bb9",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9bc5e7c-8550-4ea2-833d-d0f8d5167c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5732667-fd32-4932-b827-53e9499c861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a46a6a7-7b33-4ccb-8954-892f5cc6ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- c: string (nullable = true)\n",
      " |-- d: date (nullable = true)\n",
      " |-- e: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2f7298b-8e46-4a3e-a87e-e2e90a07cbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'bigint'),\n",
       " ('b', 'double'),\n",
       " ('c', 'string'),\n",
       " ('d', 'date'),\n",
       " ('e', 'timestamp')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658f926-5ccc-46cb-84a9-a3d042382d42",
   "metadata": {},
   "source": [
    "## Selecting and Accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "147c2c2c-d231-4439-8bae-6ee1221f95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.withColumn('upper_c', upper(df.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d8b3ce8-978a-4aa0-a18c-0e127d82b723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  a|  b|      c|         d|                  e|upper_c|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0675f19e-f178-4371-81a8-797d166b2f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  a|  b|      c|         d|                  e|upper_c|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n",
      "+---+---+-------+----------+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('upper_c', upper(df.c)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb48a94f-e8d5-447f-8048-7ac9ead56ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfc48d90-3e7d-4ec1-8074-ae1a705033dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      c|\n",
      "+-------+\n",
      "|string1|\n",
      "|string2|\n",
      "|string3|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"c\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf80977-901a-4b54-9a01-5147eb1b8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.a == 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1d9be-a4ef-4f1e-9a25-26b79ff07403",
   "metadata": {},
   "source": [
    "## Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3e71ee9-c9de-4930-849b-31920f9dc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame([\n",
    "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
    "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
    "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb60f23b-55a7-409b-9527-74ea5e4f3fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- color: string (nullable = true)\n",
      " |-- fruit: string (nullable = true)\n",
      " |-- v1: long (nullable = true)\n",
      " |-- v2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "505328c2-a810-4df5-a2f6-e81e390d8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+---+\n",
      "|color| fruit| v1| v2|\n",
      "+-----+------+---+---+\n",
      "|  red|banana|  1| 10|\n",
      "| blue|banana|  2| 20|\n",
      "|  red|carrot|  3| 30|\n",
      "| blue| grape|  4| 40|\n",
      "|  red|carrot|  5| 50|\n",
      "|black|carrot|  6| 60|\n",
      "|  red|banana|  7| 70|\n",
      "|  red| grape|  8| 80|\n",
      "+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e00452e3-d800-4d1a-b5b8-e3c0650c78b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|color|avg(v1)|avg(v2)|\n",
      "+-----+-------+-------+\n",
      "|  red|    4.8|   48.0|\n",
      "|black|    6.0|   60.0|\n",
      "| blue|    3.0|   30.0|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('color').avg().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e636c-a553-4210-91fb-915dc2f872ae",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c093a83-9683-42b4-8319-ca927cdd6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.read.text(\"/opt/spark/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6862071-da24-4e58-b2a0-70d66a842838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|      # Apache Spark|\n",
      "|                    |\n",
      "|Spark is a unifie...|\n",
      "|high-level APIs i...|\n",
      "|supports general ...|\n",
      "|rich set of highe...|\n",
      "|MLlib for machine...|\n",
      "|and Structured St...|\n",
      "|                    |\n",
      "|<https://spark.ap...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbcffa7d-6e14-488f-9502-ac6fbb5b719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = lines.withColumn(\"words\", split(col(\"value\"), \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea6c383c-55e2-43c5-acfb-69eb5648357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               value|               words|\n",
      "+--------------------+--------------------+\n",
      "|      # Apache Spark|  [#, Apache, Spark]|\n",
      "|                    |                  []|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|\n",
      "|high-level APIs i...|[high-level, APIs...|\n",
      "|supports general ...|[supports, genera...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7511f476-c4e6-4dd3-9110-1f6faf1d18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc9c0669-d1be-4230-81c7-d479563e9c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|               value|          wordsArray|      words|\n",
      "+--------------------+--------------------+-----------+\n",
      "|      # Apache Spark|  [#, Apache, Spark]|          #|\n",
      "|      # Apache Spark|  [#, Apache, Spark]|     Apache|\n",
      "|      # Apache Spark|  [#, Apache, Spark]|      Spark|\n",
      "|                    |                  []|           |\n",
      "|Spark is a unifie...|[Spark, is, a, un...|      Spark|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|         is|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|          a|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|    unified|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|  analytics|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|     engine|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|        for|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|large-scale|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|       data|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|processing.|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|         It|\n",
      "|Spark is a unifie...|[Spark, is, a, un...|   provides|\n",
      "|high-level APIs i...|[high-level, APIs...| high-level|\n",
      "|high-level APIs i...|[high-level, APIs...|       APIs|\n",
      "|high-level APIs i...|[high-level, APIs...|         in|\n",
      "|high-level APIs i...|[high-level, APIs...|     Scala,|\n",
      "+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = lines.withColumn(\"wordsArray\", split(col(\"value\"), \" \")).withColumn(\"words\", explode(\"wordsArray\"))\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f292118-daea-41bb-86ac-7d43a0e13c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|    words|count|\n",
      "+---------+-----+\n",
      "|         |   73|\n",
      "|      the|   23|\n",
      "|       to|   16|\n",
      "|    Spark|   14|\n",
      "|      for|   12|\n",
      "|        a|    9|\n",
      "|      and|    9|\n",
      "|       ##|    9|\n",
      "|      run|    7|\n",
      "|       on|    7|\n",
      "|       is|    7|\n",
      "|      can|    6|\n",
      "|     also|    5|\n",
      "|       of|    5|\n",
      "|       in|    5|\n",
      "|      you|    4|\n",
      "|       an|    4|\n",
      "|   Please|    4|\n",
      "|        *|    4|\n",
      "|including|    4|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = words.groupBy(col(\"words\")).count()\n",
    "counts.orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c19ca88f-b747-4bce-8c38-aca251a71960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(words='[![PySpark', count=1),\n",
       " Row(words='online', count=1),\n",
       " Row(words='graphs', count=1),\n",
       " Row(words='[\"Building', count=1),\n",
       " Row(words='documentation', count=3),\n",
       " Row(words='command,', count=2),\n",
       " Row(words='abbreviated', count=1),\n",
       " Row(words='overview', count=1),\n",
       " Row(words='rich', count=1),\n",
       " Row(words='set', count=2),\n",
       " Row(words='-DskipTests', count=1),\n",
       " Row(words='1,000,000,000:', count=2),\n",
       " Row(words='name', count=1),\n",
       " Row(words='[\"Specifying', count=1),\n",
       " Row(words='stream', count=1),\n",
       " Row(words='run:', count=1),\n",
       " Row(words='not', count=1),\n",
       " Row(words='programs', count=2),\n",
       " Row(words='tests', count=2),\n",
       " Row(words='./dev/run-tests', count=1),\n",
       " Row(words='will', count=1),\n",
       " Row(words='[run', count=1),\n",
       " Row(words='particular', count=2),\n",
       " Row(words='Alternatively,', count=1),\n",
       " Row(words='must', count=1),\n",
       " Row(words='using', count=3),\n",
       " Row(words='./build/mvn', count=1),\n",
       " Row(words='you', count=4),\n",
       " Row(words='MLlib', count=1),\n",
       " Row(words='DataFrames,', count=1),\n",
       " Row(words='variable', count=1),\n",
       " Row(words='Note', count=1),\n",
       " Row(words='core', count=1),\n",
       " Row(words='protocols', count=1),\n",
       " Row(words='Guide](https://spark.apache.org/docs/latest/configuration.html)', count=1),\n",
       " Row(words='guidance', count=2),\n",
       " Row(words='shell:', count=2),\n",
       " Row(words='can', count=6),\n",
       " Row(words='site,', count=1),\n",
       " Row(words='*', count=4),\n",
       " Row(words='systems.', count=1),\n",
       " Row(words='[building', count=1),\n",
       " Row(words='configure', count=1),\n",
       " Row(words='for', count=12),\n",
       " Row(words='README', count=1),\n",
       " Row(words='Interactive', count=2),\n",
       " Row(words='how', count=3),\n",
       " Row(words='[Configuration', count=1),\n",
       " Row(words='Hive', count=2),\n",
       " Row(words='provides', count=1),\n",
       " Row(words='Hadoop-supported', count=1),\n",
       " Row(words='pre-built', count=1),\n",
       " Row(words='[\"Useful', count=1),\n",
       " Row(words='directory.', count=1),\n",
       " Row(words='Example', count=1),\n",
       " Row(words='example', count=3),\n",
       " Row(words='Kubernetes', count=1),\n",
       " Row(words='one', count=2),\n",
       " Row(words='MASTER', count=1),\n",
       " Row(words='guide](https://spark.apache.org/contributing.html)', count=1),\n",
       " Row(words='in', count=5),\n",
       " Row(words='library', count=1),\n",
       " Row(words='Spark.', count=1),\n",
       " Row(words='contains', count=1),\n",
       " Row(words='Configuration', count=1),\n",
       " Row(words='programming', count=1),\n",
       " Row(words='with', count=3),\n",
       " Row(words='contributing', count=1),\n",
       " Row(words='downloaded', count=1),\n",
       " Row(words='1000).count()', count=2),\n",
       " Row(words='comes', count=1),\n",
       " Row(words='machine', count=1),\n",
       " Row(words='building', count=2),\n",
       " Row(words='params', count=1),\n",
       " Row(words='given.', count=1),\n",
       " Row(words='be', count=2),\n",
       " Row(words='same', count=1),\n",
       " Row(words='integration', count=1),\n",
       " Row(words='Programs', count=1),\n",
       " Row(words='locally', count=2),\n",
       " Row(words='using:', count=1),\n",
       " Row(words='[Apache', count=1),\n",
       " Row(words='your', count=1),\n",
       " Row(words='optimized', count=1),\n",
       " Row(words='Developer', count=1),\n",
       " Row(words='R,', count=1),\n",
       " Row(words='[![AppVeyor', count=1),\n",
       " Row(words='should', count=2),\n",
       " Row(words='graph', count=1),\n",
       " Row(words='package', count=1),\n",
       " Row(words='[project', count=1),\n",
       " Row(words='project', count=1),\n",
       " Row(words='`examples`', count=2),\n",
       " Row(words='resource-managers/kubernetes/integration-tests/README.md', count=1),\n",
       " Row(words='versions', count=1),\n",
       " Row(words='Spark\"](https://spark.apache.org/docs/latest/building-spark.html).', count=1),\n",
       " Row(words='Spark](#building-spark).', count=1),\n",
       " Row(words='general', count=2),\n",
       " Row(words='other', count=1),\n",
       " Row(words='1000', count=2),\n",
       " Row(words='learning,', count=1),\n",
       " Row(words='when', count=1),\n",
       " Row(words='submit', count=1),\n",
       " Row(words='Apache', count=1),\n",
       " Row(words='detailed', count=2),\n",
       " Row(words='About', count=1),\n",
       " Row(words='is', count=7),\n",
       " Row(words='on', count=7),\n",
       " Row(words='scala>', count=1),\n",
       " Row(words='print', count=1),\n",
       " Row(words='Tools\"](https://spark.apache.org/developer-tools.html).', count=1),\n",
       " Row(words='use', count=3),\n",
       " Row(words='different', count=1),\n",
       " Row(words='following', count=2),\n",
       " Row(words='YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)', count=1),\n",
       " Row(words='<https://spark.apache.org/>', count=1),\n",
       " Row(words='SparkPi', count=2),\n",
       " Row(words='refer', count=2),\n",
       " Row(words='./bin/run-example', count=2),\n",
       " Row(words='data', count=2),\n",
       " Row(words='Tests', count=1),\n",
       " Row(words='Versions', count=1),\n",
       " Row(words='processing.', count=2),\n",
       " Row(words='its', count=1),\n",
       " Row(words='tests](https://spark.apache.org/developer-tools.html#individual-tests).', count=1),\n",
       " Row(words='basic', count=1),\n",
       " Row(words='latest', count=1),\n",
       " Row(words='only', count=1),\n",
       " Row(words='<class>', count=1),\n",
       " Row(words='have', count=1),\n",
       " Row(words='runs.', count=1),\n",
       " Row(words='You', count=3),\n",
       " Row(words='tips,', count=1),\n",
       " Row(words='project.', count=1),\n",
       " Row(words='developing', count=1),\n",
       " Row(words='YARN,', count=1),\n",
       " Row(words='It', count=2),\n",
       " Row(words='\"local\"', count=1),\n",
       " Row(words='processing,', count=1),\n",
       " Row(words='built', count=1),\n",
       " Row(words='Pi', count=1),\n",
       " Row(words='thread,', count=1),\n",
       " Row(words='A', count=1),\n",
       " Row(words='APIs', count=1),\n",
       " Row(words='Scala,', count=1),\n",
       " Row(words='file', count=1),\n",
       " Row(words='computation', count=1),\n",
       " Row(words='Once', count=1),\n",
       " Row(words='find', count=1),\n",
       " Row(words='the', count=23),\n",
       " Row(words='To', count=2),\n",
       " Row(words='uses', count=1),\n",
       " Row(words='Version', count=1),\n",
       " Row(words='N', count=1),\n",
       " Row(words='programs,', count=1),\n",
       " Row(words='\"yarn\"', count=1),\n",
       " Row(words='see', count=3),\n",
       " Row(words='./bin/pyspark', count=1),\n",
       " Row(words='Structured', count=1),\n",
       " Row(words='[![Jenkins', count=1),\n",
       " Row(words='return', count=2),\n",
       " Row(words='Java,', count=1),\n",
       " Row(words='from', count=1),\n",
       " Row(words='Because', count=1),\n",
       " Row(words='Streaming', count=1),\n",
       " Row(words='More', count=1),\n",
       " Row(words='cluster', count=1),\n",
       " Row(words='analytics', count=1),\n",
       " Row(words='analysis.', count=1),\n",
       " Row(words='cluster.', count=1),\n",
       " Row(words='Running', count=1),\n",
       " Row(words='Please', count=4),\n",
       " Row(words='talk', count=1),\n",
       " Row(words='distributions.', count=1),\n",
       " Row(words='guide,', count=1),\n",
       " Row(words='There', count=1),\n",
       " Row(words='\"local[N]\"', count=1),\n",
       " Row(words='Try', count=1),\n",
       " Row(words='and', count=9),\n",
       " Row(words='do', count=2),\n",
       " Row(words='Scala', count=2),\n",
       " Row(words='class', count=2),\n",
       " Row(words='build', count=3),\n",
       " Row(words='setup', count=1),\n",
       " Row(words='need', count=1),\n",
       " Row(words='spark://', count=1),\n",
       " Row(words='Hadoop,', count=2),\n",
       " Row(words='Thriftserver', count=1),\n",
       " Row(words='are', count=1),\n",
       " Row(words='requires', count=1),\n",
       " Row(words='package.', count=1),\n",
       " Row(words='Enabling', count=1),\n",
       " Row(words='clean', count=1),\n",
       " Row(words='large-scale', count=1),\n",
       " Row(words='high-level', count=1),\n",
       " Row(words='SQL', count=2),\n",
       " Row(words='page](https://spark.apache.org/documentation.html).', count=1),\n",
       " Row(words='against', count=1),\n",
       " Row(words='of', count=5),\n",
       " Row(words='through', count=1),\n",
       " Row(words='review', count=1),\n",
       " Row(words='package.)', count=1),\n",
       " Row(words='Python,', count=2),\n",
       " Row(words='easiest', count=1),\n",
       " Row(words='no', count=1),\n",
       " Row(words='Testing', count=1),\n",
       " Row(words='several', count=1),\n",
       " Row(words='help', count=1),\n",
       " Row(words='The', count=1),\n",
       " Row(words='sample', count=1),\n",
       " Row(words='MASTER=spark://host:7077', count=1),\n",
       " Row(words='examples', count=2),\n",
       " Row(words='an', count=4),\n",
       " Row(words='#', count=1),\n",
       " Row(words='Online', count=1),\n",
       " Row(words='test,', count=1),\n",
       " Row(words='including', count=4),\n",
       " Row(words='usage', count=1),\n",
       " Row(words='Python', count=2),\n",
       " Row(words='at', count=2),\n",
       " Row(words='development', count=1),\n",
       " Row(words='IDE,', count=1),\n",
       " Row(words='way', count=1),\n",
       " Row(words='Contributing', count=1),\n",
       " Row(words='get', count=1),\n",
       " Row(words='that', count=2),\n",
       " Row(words='##', count=9),\n",
       " Row(words='For', count=3),\n",
       " Row(words='prefer', count=1),\n",
       " Row(words='This', count=2),\n",
       " Row(words='running', count=1),\n",
       " Row(words='Build](https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&logo=appveyor)](https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark)', count=1),\n",
       " Row(words='web', count=1),\n",
       " Row(words='run', count=7),\n",
       " Row(words='locally.', count=1),\n",
       " Row(words='Spark', count=14),\n",
       " Row(words='URL,', count=1),\n",
       " Row(words='a', count=9),\n",
       " Row(words='higher-level', count=1),\n",
       " Row(words='tools', count=1),\n",
       " Row(words='if', count=4),\n",
       " Row(words='available', count=1),\n",
       " Row(words='', count=73),\n",
       " Row(words='Documentation', count=1),\n",
       " Row(words='this', count=1),\n",
       " Row(words='Maven](https://maven.apache.org/).', count=1),\n",
       " Row(words='(You', count=1),\n",
       " Row(words='Build](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7-hive-2.3/badge/icon)](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7-hive-2.3)', count=1),\n",
       " Row(words='>>>', count=1),\n",
       " Row(words='information', count=1),\n",
       " Row(words='info', count=1),\n",
       " Row(words='unified', count=1),\n",
       " Row(words='Shell', count=2),\n",
       " Row(words='environment', count=1),\n",
       " Row(words='built,', count=1),\n",
       " Row(words='module,', count=1),\n",
       " Row(words='them,', count=1),\n",
       " Row(words='`./bin/run-example', count=1),\n",
       " Row(words='instance:', count=1),\n",
       " Row(words='first', count=1),\n",
       " Row(words='[Contribution', count=1),\n",
       " Row(words='documentation,', count=1),\n",
       " Row(words='[params]`.', count=1),\n",
       " Row(words='mesos://', count=1),\n",
       " Row(words='engine', count=2),\n",
       " Row(words='GraphX', count=1),\n",
       " Row(words='example:', count=1),\n",
       " Row(words='HDFS', count=1),\n",
       " Row(words='or', count=3),\n",
       " Row(words='to', count=16),\n",
       " Row(words='Hadoop', count=3),\n",
       " Row(words='individual', count=1),\n",
       " Row(words='also', count=5),\n",
       " Row(words='changed', count=1),\n",
       " Row(words='started', count=1),\n",
       " Row(words='./bin/spark-shell', count=1),\n",
       " Row(words='threads.', count=1),\n",
       " Row(words='supports', count=2),\n",
       " Row(words='storage', count=1),\n",
       " Row(words='version', count=1),\n",
       " Row(words='instructions.', count=1),\n",
       " Row(words='Building', count=1),\n",
       " Row(words='start', count=1),\n",
       " Row(words='Many', count=1),\n",
       " Row(words='which', count=2),\n",
       " Row(words='Coverage](https://img.shields.io/badge/dynamic/xml.svg?label=pyspark%20coverage&url=https%3A%2F%2Fspark-test.github.io%2Fpyspark-coverage-site&query=%2Fhtml%2Fbody%2Fdiv%5B1%5D%2Fdiv%2Fh1%2Fspan&colorB=brightgreen&style=plastic)](https://spark-test.github.io/pyspark-coverage-site)', count=1),\n",
       " Row(words='spark.range(1000', count=2),\n",
       " Row(words='And', count=1),\n",
       " Row(words='distribution', count=1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = counts.collect()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d08071d-961d-48c4-98ff-9a64bf1a5708",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cef8b43-f2ab-422c-9d6d-f0ceb124e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|    8|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.createOrReplaceTempView(\"tableA\")\n",
    "spark.sql(\"SELECT count(*) as count from tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ce52b81-6f1e-4006-b68b-f2ebdaecaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bdc14-b982-4547-a7c0-0ecafd2bdc39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
